<meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=no">
<link rel="manifest" href="mustache.json">
<title>Mustache</title>
<style>
  html, body {
    margin: 0 auto;
    height: 100%;
    background: rgb(51, 51, 58);
    color: #fff;
    user-select: none;
  }
  video {
    display: none;
  }
  canvas {
    width: 100vw;
    height: 100vh;
  }
  pre {
    position: absolute;
    top: 24px;
    left: 24px;
    white-space: pre-line;
    right: 24px;
    text-shadow: 0 0 black;
   }
  .recording #recordButton {
    transform: scale(3);
    background: red;
    font-size: 0;
  }
  #mustache {
    display: none;
  }
  .bottomBar {
    position: absolute;
    bottom: 0;
    right: 0;
    left: 0;
    height: 128px;
    background-color: rgba(51, 51, 58, 0.3);
  }
  #recordButton {
    will-change: transform, background;
    transition: transform .1s ease-out;
    position: absolute;
    bottom: 36px;
    right: 0;
    text-align: center;
    left: 0;
    width: 64px;
    margin: auto;
    background: rgb(7, 104, 125);
    line-height: 64px;
    border-radius: 50%;
    box-shadow: 0 0 2px 0 rgb(51, 51, 58);
  }
</style>
<canvas id="canvas"></canvas>
<video id="video" autoplay muted></video>
<div class="bottomBar"></div>
<img id="mustache" src="mustache.png">
<div id="recordButton">&#9210;</div>
<pre id="log"></pre>
<div id="debug" style="position: absolute; background-color: rgba(0, 0, 0, 0.5); border-radius: 4px; bottom: 138px; padding: 4px; color: white; left: 6px; display: none">
  <input type="checkbox" id="canvasSize" onchange="changeCanvasSize()"><label for="canvasSize">Big Canvas</label><br/>
  <input type="checkbox" id="mirror" onchange="changeMirror()"><label for="mirror">Mirror</label><br/>
  <input type="checkbox" checked id="detectFaces" onchange="changeDetectFaces()"><label for="detectFaces">Detect Faces</label><br/>
  <input type="checkbox" checked id="webWorker" onchange="changeWebWorker()"><label for="webWorker">Web Worker</label><br/>
</div>
<script>

/* Debug stuff */
document.querySelector('.bottomBar').addEventListener('click', event => {
  debug.style.display = (debug.style.display === 'none') ? 'block' : 'none';
});

function changeCanvasSize() {
  if (canvasSize.checked) {
    canvas.height = window.innerHeight * devicePixelRatio;
    canvas.width = window.innerWidth * devicePixelRatio;
  } else {
    canvas.height = window.innerHeight;
    canvas.width = window.innerWidth;
  }
  // HACK: Face Detector doesn't accept canvas whose width is odd.
  if (canvas.width % 2 == 1) {
    canvas.width += 1;
  }
  log.textContent = `Video: ${video.videoWidth}x${video.videoHeight}, Canvas: ${canvas.width}x${canvas.height}`;
}

function changeDetectFaces() {
  log.textContent = '';
  if (!detectFaces.checked) {
    worker = null;
    faces = [];
    isDetectingFaces = true;
  } else {
    isDetectingFaces = false;
    worker = new Worker('mustache.js');
    worker.addEventListener('message', event => {
      if (event.data.error) {
        faces = [];
        log.textContent = event.data.error;
      } else if (event.data.faces.length) {
        faces = JSON.parse(event.data.faces);
      }
      isDetectingFaces = false;
    });
  }
}

function changeWebWorker() {
  log.textContent = '';
  isDetectingFaces = false;
  if (!webWorker.checked) {
    worker = null;
    faces = [];
  } else {
    worker = new Worker('mustache.js');
    worker.addEventListener('message', event => {
      if (event.data.error) {
        faces = [];
        log.textContent = event.data.error;
      } else if (event.data.faces.length) {
        faces = JSON.parse(event.data.faces);
      }
      isDetectingFaces = false;
    });
  }
}

function changeMirror() {
  // Mustaches look great in mirrors.
  canvas.getContext('2d').translate(canvas.width, 0);
  canvas.getContext('2d').scale(-1, 1);
}

/* End of Debug stuff */

let faces = [];

let recorder;
let chunks = [];

let isDetectingFaces = false;

let worker = new Worker('mustache.js');

(async _ => {
  // Grab camera stream.
  const constraints = {
     video: {
       facingMode: 'user',
       frameRate: 60,
       width: 4048,
       height: 3036,
     }
  };
  video.srcObject = await navigator.mediaDevices.getUserMedia(constraints);
  await video.play();

  canvas.height = window.innerHeight;
  canvas.width = window.innerWidth;
  // HACK: Face Detector doesn't accept canvas whose width is odd.
  if (canvas.width % 2 == 1) {
    canvas.width += 1;
  }

  requestAnimationFrame(draw);

  recordButton.addEventListener('pointerenter', startRecording);
  recordButton.addEventListener('pointerout', stopRecording);
})();

async function draw() {
  requestAnimationFrame(draw);

  const context = canvas.getContext('2d');

  // Draw video frame.
  const ratio  = Math.max(canvas.width / video.videoWidth, canvas.height / video.videoHeight);
  context.drawImage(video, 0, 0, video.videoWidth, video.videoHeight,
      (canvas.width - video.videoWidth * ratio) / 2, 0,
      video.videoWidth * ratio, video.videoHeight * ratio);  

  // Draw mustache on previously detected face.
  if (faces.length) {
    const face = faces[0];
    context.drawImage(mustache,
        face.left,
        face.bottom - mustache.height * face.width / mustache.width / 2,
        face.width,
        mustache.height * face.width / mustache.width);
  }

  // Detect new faces.
  if (!isDetectingFaces) {
    isDetectingFaces = true;
    if (worker) {
      const imageData = context.getImageData(0, 0, canvas.width, canvas.height);
      // Send video frame to worker for detection work.
      worker.postMessage(imageData);
    } else {
      const faceDetector = new FaceDetector({ fastMode: true, maxDetectedFaces: 1 });
      const detectedFaces = await faceDetector.detect(canvas);
      if (detectedFaces.length) {
        // Let's overwrite faces only when new ones are found.
        faces = detectedFaces.map(face => face.boundingBox);
      }
      isDetectingFaces = false;
    }
  }
}

worker.addEventListener('message', event => {
  if (event.data.error) {
    log.textContent = event.data.error;
    faces = [];
  } else if (event.data.faces.length) {
    // Let's overwrite faces only when new ones are found.
    faces = JSON.parse(event.data.faces);
  }
  isDetectingFaces = false;
});

function startRecording() {
  const stream = canvas.captureStream();
  recorder = new MediaRecorder(stream, { mimeType: 'video/webm;codecs=h264' });
  recorder.start(10); // collect 10ms of data
  recorder.addEventListener('dataavailable', event => { chunks.push(event.data); });
  recorder.addEventListener('stop', event => {
    const blob = new Blob(chunks, { type: 'video/webm' });
    window.open(URL.createObjectURL(blob));
    recorder = null;
    //uploadVideo(blob);
  });
  document.body.classList.toggle('recording');
}

function stopRecording() {
  recorder.stop();
  document.body.classList.toggle('recording');
}

function uploadVideo(blob) {
  const formData = new FormData();
  formData.append('key', 'AIzaSyDy2L3xfde9x9uwAIF4QMSmDVtQfJ0Wm8s');
  formData.append('attachment', blob, 'aRandomFileName');

  // Upload video to Google Cloud Storage.
  fetch('https://www.googleapis.com/upload/storage/v1/b/pwa-mustache/o?uploadType=media&name=foo', {
    method: 'POST', 
    body: formData,
    headers: new Headers({
      'Content-Type': 'video/webm',
      'Content-Length': blob.length
    })
  })
  .then(response => {
    console.log(response);
  });
}

window.addEventListener('unhandledrejection', event => {
  log.textContent = event.reason;
});
</script>

