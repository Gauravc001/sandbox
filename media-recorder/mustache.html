<meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=no">
<title>Mustache</title>
<style>
  html, body {
    margin: 0 auto;
    height: 100%;
    background: rgb(51, 51, 58);
    color: #fff;
  }
  video {
    display: none;
  }
  canvas {
    width: 100vw;
    height: 100vh;
  }
  pre {
    position: absolute;
    top: 24px;
    left: 24px;
    white-space: pre-line;
    right: 24px;
    text-shadow: 0 0 black;
   }
  .recording {
    background-color: #F44336;
  }
  #mustache {
    display: none;
  }
  #recordButton {
    position: absolute;
    bottom: 48px;
    right: 0;
    text-align: center;
    left: 0;
    width: 64px;
    margin: auto;
    font-size: 48px;
    background: rgba(0, 193, 233, 0.5);
    line-height: 64px;
    border-radius: 50%;
    box-shadow: 0 0 4px 2px rgb(51, 51, 58);
  }
</style>
<canvas id="canvas"></canvas>
<video id="video" autoplay muted></video>
<img id="mustache" src="mustache.png">
<div id="recordButton">&#9210;</div>
<pre id="log"></pre>
<script>

let faces = [];

let recorder;
let chunks = [];

let isDetectingFaces = false;

(async _ => {

  // Grab camera stream.
  const constraints = {
     video: { facingMode: 'user' }
  };
  video.srcObject = await navigator.mediaDevices.getUserMedia(constraints);
  await video.play();

  canvas.width = window.innerWidth; // * devicePixelRatio;
  canvas.height = window.innerHeight; // * devicePixelRatio;
  requestAnimationFrame(draw);

  recordButton.addEventListener('click', onRecordButtonClick);

})();

async function draw() {
  requestAnimationFrame(draw);

  const context = canvas.getContext('2d');
  context.clearRect(0, 0, canvas.width, canvas.height);

  // Draw video frame.
  const ratio  = Math.min(canvas.width / video.videoWidth, canvas.height / video.videoHeight);
  context.drawImage(video, 0, 0, video.videoWidth, video.videoHeight,
      (canvas.width - video.videoWidth * ratio) / 2, 0,
      video.videoWidth * ratio, video.videoHeight * ratio);  

  const faceDetector = new FaceDetector({ fastMode: true, maxDetectedFaces: 1 });
  const imageData = context.getImageData(0, 0, canvas.width, canvas.height);

  // Draw mustaches on previously detected faces.
  for (const face of faces) {
    context.drawImage(mustache,
        face.boundingBox.left,
        face.boundingBox.bottom - mustache.height * face.boundingBox.width / mustache.width / 2,
        face.boundingBox.width,
        mustache.height * face.boundingBox.width / mustache.width);
  }

  // Detect new faces.
  if (!isDetectingFaces) {
    isDetectingFaces = true;
    faces = await faceDetector.detect(imageData);
    isDetectingFaces = false;
  }
}

function onRecordButtonClick(event) {
  if (document.body.classList.toggle('recording')) {
    const stream = canvas.captureStream();
    recorder = new MediaRecorder(stream, { mimeType: 'video/webm;codecs=h264' });
    recorder.start(10); // collect 10ms of data
    recorder.addEventListener('dataavailable', event => { chunks.push(event.data); });
    recorder.addEventListener('stop', event => {
      const blob = new Blob(chunks, { type: 'video/webm' });
      window.open(URL.createObjectURL(blob));
      //uploadVideo(blob);
    });
  } else {
    recorder.stop();
  }
}

function uploadVideo(blob) {
  const formData = new FormData();
  formData.append('key', 'AIzaSyDy2L3xfde9x9uwAIF4QMSmDVtQfJ0Wm8s');
  formData.append('attachment', blob, 'aRandomFileName');

  // Upload video to Google Cloud Storage.
  fetch('https://www.googleapis.com/upload/storage/v1/b/pwa-mustache/o?uploadType=media&name=foo', {
    method: 'POST', 
    body: formData,
    headers: new Headers({
      'Content-Type': 'video/webm',
      'Content-Length': blob.length
    })
  })
  .then(response => {
    console.log(response);
  });
}

window.addEventListener('unhandledrejection', event => {
  log.textContent = event.reason;
});
</script>

