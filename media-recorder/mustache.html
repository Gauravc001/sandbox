<meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=no">
<title>Mustache</title>
<style>
  html, body {
    margin: 0 auto;
    height: 100%;
    background: rgb(51, 51, 58);
    color: #fff;
  }
  video {
    display: none;
  }
  canvas {
    width: 100vw;
    height: 100vh;
  }
  pre {
    position: absolute;
    top: 24px;
    left: 24px;
    white-space: pre-line;
    right: 24px;
    text-shadow: 0 0 black;
   }
  .recording {
    background-color: #F44336;
  }
  #mustache {
    display: none;
  }
  #recordButton {
    position: absolute;
    bottom: 36px;
    right: 0;
    text-align: center;
    left: 0;
    width: 64px;
    margin: auto;
    font-size: 48px;
    background: rgba(0, 193, 233, 0.5);
    line-height: 64px;
    border-radius: 50%;
    box-shadow: 0 0 4px 2px rgb(51, 51, 58);
  }
</style>
<canvas id="canvas"></canvas>
<video id="video" autoplay muted></video>
<img id="mustache" src="mustache.png">
<div id="recordButton">&#9210;</div>
<pre id="log"></pre>
<script>

let faces = [];

let recorder;
let chunks = [];

let isDetectingFaces = false;

let worker = new Worker('mustache.js');

(async _ => {
  // Grab camera stream.
  const constraints = {
     video: {
       facingMode: 'user',
       frameRate: 60,
       height: 1080,
     }
  };
  video.srcObject = await navigator.mediaDevices.getUserMedia(constraints);
  console.log(video.srcObject.getTracks()[0].getSettings());
  await video.play();

  canvas.width = window.innerWidth; // * devicePixelRatio;
  canvas.height = window.innerHeight; // * devicePixelRatio;
  requestAnimationFrame(draw);

  recordButton.addEventListener('click', onRecordButtonClick);
})();

async function draw() {
  requestAnimationFrame(draw);

  const context = canvas.getContext('2d');
  context.clearRect(0, 0, canvas.width, canvas.height);

  // Draw video frame.
  const ratio  = Math.min(canvas.width / video.videoWidth, canvas.height / video.videoHeight);
  context.drawImage(video, 0, 0, video.videoWidth, video.videoHeight,
      (canvas.width - video.videoWidth * ratio) / 2, 0,
      video.videoWidth * ratio, video.videoHeight * ratio);  

  context.font = '16px Cousine';
  context.fillStyle = 'deeppink';
  context.textBaseline = 'top';
  context.fillText(`${video.videoWidth}x${video.videoHeight}`, 12, 12);

  // Detect new faces.
  if (!isDetectingFaces) {
    const imageData = context.getImageData(0, 0, canvas.width, canvas.height);
    // Send video frame to worker.
    worker.postMessage(imageData);
    isDetectingFaces = true;
  }

  // Draw mustaches on previously detected faces.
  for (const face of faces) {
    context.drawImage(mustache,
        face.left,
        face.bottom - mustache.height * face.width / mustache.width / 2,
        face.width,
        mustache.height * face.width / mustache.width);
  }
}

worker.addEventListener('message', event => {
  isDetectingFaces = false;
  faces = JSON.parse(event.data.faces);
});

function onRecordButtonClick(event) {
  if (document.body.classList.toggle('recording')) {
    const stream = canvas.captureStream();
    recorder = new MediaRecorder(stream, { mimeType: 'video/webm;codecs=h264' });
    recorder.start(10); // collect 10ms of data
    recorder.addEventListener('dataavailable', event => { chunks.push(event.data); });
    recorder.addEventListener('stop', event => {
      const blob = new Blob(chunks, { type: 'video/webm' });
      window.open(URL.createObjectURL(blob));
      //uploadVideo(blob);
    });
  } else {
    recorder.stop();
  }
}

function uploadVideo(blob) {
  const formData = new FormData();
  formData.append('key', 'AIzaSyDy2L3xfde9x9uwAIF4QMSmDVtQfJ0Wm8s');
  formData.append('attachment', blob, 'aRandomFileName');

  // Upload video to Google Cloud Storage.
  fetch('https://www.googleapis.com/upload/storage/v1/b/pwa-mustache/o?uploadType=media&name=foo', {
    method: 'POST', 
    body: formData,
    headers: new Headers({
      'Content-Type': 'video/webm',
      'Content-Length': blob.length
    })
  })
  .then(response => {
    console.log(response);
  });
}


/**
 * By Ken Fyrstenberg Nilsen
 *
 * drawImageProp(context, image [, x, y, width, height [,offsetX, offsetY]])
 *
 * If image and context are only arguments rectangle will equal canvas
*/
function drawImageProp(ctx, img, x, y, w, h, offsetX, offsetY) {

    if (arguments.length === 2) {
        x = y = 0;
        w = ctx.canvas.width;
        h = ctx.canvas.height;
    }

    // default offset is center
    offsetX = typeof offsetX === "number" ? offsetX : 0.5;
    offsetY = typeof offsetY === "number" ? offsetY : 0.5;

    // keep bounds [0.0, 1.0]
    if (offsetX < 0) offsetX = 0;
    if (offsetY < 0) offsetY = 0;
    if (offsetX > 1) offsetX = 1;
    if (offsetY > 1) offsetY = 1;

    var iw = video.videoWidth,
        ih = video.videoHeight,
        r = Math.min(w / iw, h / ih),
        nw = iw * r,   // new prop. width
        nh = ih * r,   // new prop. height
        cx, cy, cw, ch, ar = 1;

    // decide which gap to fill    
    if (nw < w) ar = w / nw;                             
    if (Math.abs(ar - 1) < 1e-14 && nh < h) ar = h / nh;  // updated
    nw *= ar;
    nh *= ar;

    // calc source rectangle
    cw = iw / (nw / w);
    ch = ih / (nh / h);

    cx = (iw - cw) * offsetX;
    cy = (ih - ch) * offsetY;

    // make sure source rectangle is valid
    if (cx < 0) cx = 0;
    if (cy < 0) cy = 0;
    if (cw > iw) cw = iw;
    if (ch > ih) ch = ih;

    // fill image in dest. rectangle
    ctx.drawImage(video, cx, cy, cw, ch,  x, y, w, h);
}

window.addEventListener('unhandledrejection', event => {
  log.textContent = event.reason;
});
</script>

